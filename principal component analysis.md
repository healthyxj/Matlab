# 主成分变换
## 1、相关概念的复习
特征值和特征向量

Aξ=λξ 

矢量ξ在矩阵A的变换作用后与原矢量平行，仅仅在尺度上变为原来的λ倍。称ξ是A的一个特征矢量，λ是对应的特征值。 
~~~
求矩阵的特征值和特征向量
构造函数f(x) = |λE-A|
令f(x) = 0,λ值就是特征值，将λ带入到特征方程组(λE-A)X = 0，得到的基础解系就是特征值对应的全部特征向量。
利用这些特征向量进行线性组合就可以得到全部的特征向量。
~~~

## 2、主成分分析
PCA是Principal component analysis的缩写，中文翻译为主元分析。主元分析，这种方法可以有效的找出数据 中最“主要”的元素和结构，去除噪音和冗余，将原有的复杂
数据降维，揭示隐藏在复杂数据背后的简单结构。
### 线性代数角度
PCA的目标就是使用另一组基去重新描述得到的数据空间。而新的基要能尽量揭示原有的数据间的关系。找到这样的主元就可以最大程度的去除冗余和噪音的干扰。

再具体一点，PCA回答的问题是：如何寻找到另一组正交基，它们是标准正交基的线性组合，而且能够最好的表示数据集。令X表示原数据集，X是一个m*n的矩阵，它的每一个列向量都表示一个时间点上的数据，Y表示转换以后的新的数据集表示。P是X到Y的线性转换。

P是X到Y的转换矩阵。P对X进行旋转和拉伸得到Y。P的行向量就是一组新的基，它对X进行重新表示。
### 方差与目标
线性系统中，混乱数据包含噪音、旋转与冗余。

* 噪声和旋转
  * 噪声的衡量：信噪比(signal to noise ratio)SNR，或者是方差比。
  * <b>SNR=信号的方差/噪音的方差</b>
  * 一般来说，变化较大的信息被认为是信号，变化较小的是噪音。用方差来描述变化的大小

方差大，具有较宽的分布，表示了采样点的主要分布趋势，是主信号or主要分量。方差小的一般被认为是次要分量or噪音。
* 冗余
  * 对实验结果没有影响的变量；或者该变量可以由其他变量表示，这就是数据冗余。
### 协方差矩阵
对于复杂的情况，需要协方差矩阵进行衡量和判断。σ² = (Σ(ai-a')(bi-b')) / (n-1)。A和B表示不同的观测变量所记录的一组值。

将A、B写成行向量的形式：A = [a1 a2 ……an], B = [b1 b2 …… bn]。 则协方差可以表示为σ²=AB^T / (n-1)  。 类似地，对于一组有m个观测变量， n个采样时间的采样数据X，将每个观测变量的值写成行向量，可以得到一个矩阵X = [X1 X2 …… Xm]' ; 则协方差矩阵为<b>Cx = XX^T / (n-1).Cx上的对角线元素就是对应的观测变量之间的方差。非对角线上的元素是对应的观测变量之间的协方差。</b>（方差是特殊的协方差）
~~~
对角线上元素越大，表明信号越强，变量越重要；元素越小，表明存在可能是噪音。
一般来说，初始数据的协方差矩阵总是不太好的，表现为信噪比不高且变量之间的相关度大。
~~~
### 协方差矩阵的对角化
主元分析以及协方差矩阵优化的原则是： 1）最小化变量冗余，对应于<b>协方差矩阵的非对角元素要尽量小</b>； 2）最大化信号，对应于要使<b>协方差矩阵的对角线上的元素尽可能的大。</b>

即要将协方差矩阵最终转换为一个对角矩阵。
## 3、主成分的推导和性质
### 线性代数的结论
若A为p阶实对称矩阵，则一定可以找到正交阵U，使U^-1AU为一个对角矩阵，对角线上的元素为矩阵的特征根。上述矩阵的特征根对应的单位特征向量是正交的，即U’U = 1
## 4、主成分分析的原理
### 主成分分析的步骤
基于协方差矩阵

在实际问题中， X的协方差可由样品的观测矩阵得到。
* 由X的协方差阵，求出其特征根。即解方程|Σ-λI| = 0，可得λ1到λp等特征根
* 求出特征向量
* 计算累积贡献率，给出恰当的主成分个数‘
* 计算选出的k个主成分的得分
### 数学形状和几何解释
假设我们所讨论的实际问题中，有p个指标，我们把这p个指标看作p个变量，记为X1，X2，…，Xp，主成分分析就是要把这p个指标的问题，转变为讨论p个指标的线性组合的问题，而这些新的指标Y1，Y2，…，Yk(k≤p），按照保留主要信息量的原则充分反映原指标的信息，并且相互独立。

满足以下条件：每个主成分的系数平方和为1；主成分之间相互独立，没有重叠的信息；主成分的方差依次递减，重要性依次递减。
## 5、PCA的假设和局限
PCA的假设：
* 线形性假设
  * PCA的内部模型是线性的。这也就 决定了它能进行的主元分析之间的关系也是线性的。
* 使用中值和方差进行假设
  * 使用中值和方差进行充分的概率分布描述的模型只限于指数型概率分布模型。（例如高斯分布），也就是说，如果我们考察的数据的概率分布并不满足高斯分布或是指数型的概率分布，那么PCA将会失效。不过，所幸的是，根据中央极限定理， 现实生活中所遇到的大部分采样数据的概率分布都是遵从高斯分布的。
* 大方差具有较大的重要性
  * 数据本身具有较高的信噪比， 所以具有最高方差的一维向量就可以被看作是主元，而方差较小的变化则被认为是噪音。
* 主元正交
  * PCA方法假设主元向量之间都是正交的，从而可以利用线性代数的一系列有效的数学工具进行求解，大大提高了效率和应用的范围。
